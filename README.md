# go-robots.txt
Simple, easy to use module for robots.txt exclusion standard.

Features:
 - compatibility with [Robots Exclusion Standard](https://en.wikipedia.org/wiki/Robots_exclusion_standard)
 - compatibility with [Google Robots.txt specification](https://developers.google.com/webmasters/control-crawl-index/docs/robots_txt)
 - simple, single call invocation, like `robotstxt.CheckAccess(url, agent)`
 - caching of `robots.txt` rules
